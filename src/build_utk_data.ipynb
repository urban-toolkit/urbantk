{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import pickle\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKFileHandler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def create_attribute_dict(self, data: json) -> dict:\n",
    "        '''\n",
    "        Takes a json file and list of attributes and returns dictionary of grouped attributes in the json.\n",
    "        data: json\n",
    "        attributes: list [coordinates, indices, ids, normals, orientedEnvelope, sectionFootprint]\n",
    "        '''\n",
    "\n",
    "        # print(\"JDGBNDGJngdnD\")\n",
    "        # print(f'data-> {data}')\n",
    "        attr_dict = {\"coordinates\":[], \"indices\":[], \"normals\":[], \"ids\":[], \"orientedEnvelope\":[], \"sectionFootprint\":[], \"discardFuncInterval\": [], \"values\": []}\n",
    "        if 'data' in data.keys():\n",
    "            for point in data['data']:\n",
    "                for k, v in point['geometry'].items():\n",
    "                    if k == \"orientedEnvelope\" or k == \"sectionFootprint\":\n",
    "                        attr_dict[k].append(len(v))\n",
    "                    for val in v:\n",
    "                        if k == \"orientedEnvelope\" or k == \"sectionFootprint\":\n",
    "                            attr_dict[k].append(len(val))\n",
    "                            for val_val in val:\n",
    "                                attr_dict[k].append(float(val_val))\n",
    "                        else:\n",
    "                            attr_dict[k].append(val)\n",
    "        else:\n",
    "            for k, v in data.items():\n",
    "                attr_dict[k] = v\n",
    "        return attr_dict\n",
    "    \n",
    "    def create_utk_binary(self, attribute_dict: dict, df: json, utk_filename: str, filepath: str) -> None:\n",
    "        '''\n",
    "        Given a json and attribute dictionary, it generates a .utk file with compressed attribute data\n",
    "        attribute_dict: attribute dictionary(created from create_attribute_dict)\n",
    "        df: json\n",
    "        utk_filename: desired output file name\n",
    "        '''\n",
    "\n",
    "        # print(f'attr dict = {attribute_dict.keys()}')\n",
    "        # print(f'df = {df.keys()}')\n",
    "        _id = df['id']\n",
    "        if 'type' in df.keys(): type_of_layer = df['type']\n",
    "        if 'renderStyle' in df.keys(): render_style = df['renderStyle']\n",
    "        if 'styleKey' in df.keys(): style_key = df['styleKey']\n",
    "        if 'visible' in df.keys(): visible = df['visible']\n",
    "        if 'selectable' in df.keys(): selectable = df['selectable']\n",
    "        if 'skip' in df.keys(): skip = df['skip']\n",
    "\n",
    "\n",
    "        coordinates = attribute_dict['coordinates']\n",
    "        if len(coordinates) > 0: coordinates_type = type(coordinates[0])\n",
    "        indices = attribute_dict['indices']\n",
    "        if len(indices) > 0: indices_type = type(indices[0])\n",
    "        normals = attribute_dict['normals']\n",
    "        if len(normals) > 0: normals_type = type(normals[0])\n",
    "        ids = attribute_dict['ids']\n",
    "        if len(ids) > 0: ids_type = type(ids)\n",
    "        discardFuncInterval = attribute_dict['discardFuncInterval']\n",
    "        # if len(discardFuncInterval) > 0: discardFuncInterval_type = type(discardFuncInterval[0])\n",
    "        orientedEnvelope = attribute_dict['orientedEnvelope']\n",
    "        # if len(orientedEnvelope) > 0: orientedEnvelope_type = type(orientedEnvelope[0])\n",
    "        sectionFootprint = attribute_dict['sectionFootprint']\n",
    "        # if len(sectionFootprint) > 0: sectionFootprint_type = type(sectionFootprint[0])\n",
    "        values = attribute_dict['values']\n",
    "        if len(values) > 0: values_type = type(values[0])\n",
    "        \n",
    "        #coordinates can be pointers to binary data OR the coordinate data\n",
    "        if type(coordinates[0]) == int: packed_coordinates = struct.pack(f'{len(coordinates)}i', *coordinates)\n",
    "        elif type(coordinates[0]) == float: packed_coordinates = struct.pack(f'{len(coordinates)}d', *coordinates)\n",
    "        type_to_size = {\n",
    "            int: 'i',\n",
    "            float: 'd',\n",
    "            list: 'd'\n",
    "        }\n",
    "        # packed_coordinates = struct.pack(f'{len(coordinates)}{type_to_size[coordinates_type]}', *coordinates)\n",
    "        packed_indices = struct.pack(f'{len(indices)}i', *indices)\n",
    "        packed_normals = struct.pack(f'{len(normals)}i', *normals)\n",
    "        packed_ids = struct.pack(f'{len(ids)}i', *ids)\n",
    "        packed_discardFuncInterval = struct.pack(f'{len(discardFuncInterval)}d', *discardFuncInterval)\n",
    "        packed_values = struct.pack(f'{len(values)}d', *values)\n",
    "\n",
    "\n",
    "        packed_orientedEnvelope = b''\n",
    "        packed_orientedEnvelope_size = 0\n",
    "        for oEnvelope in orientedEnvelope:\n",
    "            if type(oEnvelope) == int:\n",
    "                packed_orientedEnvelope += struct.pack('d', float(oEnvelope))\n",
    "                packed_orientedEnvelope_size += 8\n",
    "            elif type(oEnvelope) == float:\n",
    "                packed_orientedEnvelope += struct.pack('d', oEnvelope)\n",
    "                packed_orientedEnvelope_size += 8\n",
    "        \n",
    "        packed_sectionFootprint = b''\n",
    "        packed_sectionFootprint_size = 0\n",
    "        flag = True\n",
    "        for footprint in sectionFootprint:\n",
    "            if type(footprint) == int:\n",
    "                packed_sectionFootprint += struct.pack('d', float(footprint))\n",
    "                packed_sectionFootprint_size += 8\n",
    "            elif type(footprint) == float:\n",
    "                # if flag:\n",
    "                    # print(f'encoding {footprint}')\n",
    "                packed_sectionFootprint += struct.pack('d', footprint)\n",
    "                packed_sectionFootprint_size += 8\n",
    "        \n",
    "        packed_values_size = len(values)*8\n",
    "        # packed_orientedEnvelope = pickle.dumps(orientedEnvelope)\n",
    "        # packed_sectionFootprint = pickle.dumps(sectionFootprint)\n",
    "\n",
    "        # calculate binary metadata size\n",
    "        binary_metadata_size = 0\n",
    "        for v in attribute_dict.values():\n",
    "            if len(v) > 0:\n",
    "                binary_metadata_size += 1\n",
    "        file_metadata_size = len(df.keys())-1\n",
    "\n",
    "        with open(os.path.join(filepath,utk_filename+'.utk'), 'w') as file:\n",
    "            file.write(f'{3 + file_metadata_size + binary_metadata_size}\\n')\n",
    "            file.write(f'file_metadata,{file_metadata_size}\\n')\n",
    "            file.write(f'id,{_id}\\n')\n",
    "            if 'type' in df.keys(): file.write(f'type,{type_of_layer}\\n')\n",
    "            if 'renderStyle' in df.keys(): file.write(f'renderStyle,{render_style}\\n')\n",
    "            if 'styleKey' in df.keys(): file.write(f'styleKey,{style_key}\\n')\n",
    "            if 'visible' in df.keys(): file.write(f'visible,{visible}\\n')\n",
    "            if 'selectable' in df.keys(): file.write(f'selectable,{selectable}\\n')\n",
    "            if 'skip' in df.keys(): file.write(f'skip,{skip}\\n')\n",
    "            file.write(f'binary_metadata,{binary_metadata_size}\\n')\n",
    "            if len(coordinates) > 0:\n",
    "                if type(coordinates[0]) == int:\n",
    "                    file.write(f'coordinates,{len(packed_coordinates)},i\\n')\n",
    "                elif type(coordinates[0]) == float:\n",
    "                    file.write(f'coordinates,{len(packed_coordinates)},d\\n')\n",
    "            if len(indices) > 0: file.write(f'indices,{len(packed_indices)},i\\n')\n",
    "            if len(normals) > 0: file.write(f'normals,{len(packed_normals)},i\\n')\n",
    "            if len(ids) > 0: file.write(f'ids,{len(packed_ids)},i\\n')\n",
    "            if len(discardFuncInterval) > 0: file.write(f'discardFuncInterval,{len(packed_discardFuncInterval)},d\\n')\n",
    "            if len(orientedEnvelope) > 0: file.write(f'orientedEnvelope,{packed_orientedEnvelope_size},d\\n')\n",
    "            if len(sectionFootprint) > 0: file.write(f'sectionFootprint,{packed_sectionFootprint_size},d\\n')\n",
    "            if len(values) > 0: file.write(f'values,{packed_values_size},d\\n')\n",
    "            \n",
    "            file.write(\"BINARY DATA SEPARATOR\")\n",
    "        \n",
    "        with open(os.path.join(filepath,utk_filename+'.utk'), 'ab') as file:\n",
    "            if len(coordinates) > 0: file.write(packed_coordinates)\n",
    "            if len(indices) > 0: file.write(packed_indices)\n",
    "            if len(normals) > 0: file.write(packed_normals)\n",
    "            if len(ids) > 0: file.write(packed_ids)\n",
    "    \n",
    "        if len(orientedEnvelope) > 0 or len(sectionFootprint) > 0 or len(values) > 0 or len(discardFuncInterval) > 0:\n",
    "            with open(os.path.join(filepath,utk_filename+'.utk'), 'a') as file:\n",
    "                file.write(\"FLOAT DATA BEGINS\")\n",
    "            with open(os.path.join(filepath,utk_filename+'.utk'), 'ab') as file:\n",
    "                if len(discardFuncInterval) > 0: file.write(packed_discardFuncInterval)\n",
    "                if len(orientedEnvelope) > 0: file.write(packed_orientedEnvelope)\n",
    "                if len(sectionFootprint) > 0: file.write(packed_sectionFootprint)\n",
    "                if len(values) > 0: file.write(packed_values)\n",
    "\n",
    "        print(f\"Data has been written to file {utk_filename}\\n\")\n",
    "        \n",
    "    def read_utk_binary(self, filename: str, filepath: str) -> list:\n",
    "        '''\n",
    "        Parses a .utk file to retrieve data\n",
    "        '''\n",
    "        with open(os.path.join(filepath,filename+'.utk'), 'rb') as file:\n",
    "            file_size = int(file.readline().decode('utf-8').strip())\n",
    "\n",
    "            file_metadata_size = int(file.readline().decode('utf-8').strip().split(',')[1])\n",
    "\n",
    "            # Read metadata fields\n",
    "            metadata = {}\n",
    "            for _ in range(file_metadata_size):\n",
    "                field_name, field_value = file.readline().decode('utf-8').strip().split(',')\n",
    "                metadata[field_name] = field_value\n",
    "\n",
    "            # Read binary metadata\n",
    "            binary_metadata_size = int(file.readline().decode('utf-8').strip().split(',')[1])\n",
    "            binary_metadata = {}\n",
    "            for _ in range(binary_metadata_size):\n",
    "                field_name, field_size, field_type = file.readline().decode('utf-8').strip().split(',')\n",
    "                binary_metadata[field_name] = [int(field_size), field_type]\n",
    "\n",
    "            data = {}\n",
    "            print(binary_metadata)\n",
    "            for field_name, field_info in binary_metadata.items():\n",
    "                field_size, field_type = field_info\n",
    "                if field_name in ['orientedEnvelope', 'sectionFootprint']:\n",
    "                    data[field_name] = pickle.loads(file.read(field_size))\n",
    "                elif field_name in [\"discardFuncInterval\", 'values']:\n",
    "                    data[field_name] = struct.unpack(f'{field_size // struct.calcsize(field_type)}{field_type}', file.read(field_size))\n",
    "                else:\n",
    "                    data[field_name] = struct.unpack(f'{field_size // struct.calcsize(field_type)}{field_type}', file.read(field_size))\n",
    "\n",
    "            return metadata, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utk_handler = UTKFileHandler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file buildings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/buildings.json', 'r') as file:\n",
    "    df_buildings = json.load(file)\n",
    "attr_buildings = utk_handler.create_attribute_dict(df_buildings)\n",
    "utk_handler.create_utk_binary(attr_buildings, df_buildings, \"buildings\", './downtown_manhattan 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['coordinates', 'indices', 'normals', 'ids', 'orientedEnvelope', 'sectionFootprint', 'discardFuncInterval', 'values'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_buildings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = 'discardFuncInterval'\n",
    "\n",
    "for i in range(len(attr_buildings[dddd])):\n",
    "    if type(attr_buildings[dddd][i]) != int:\n",
    "        print(\"LOL SIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coordinates': [1704, 'i'], 'indices': [1704, 'i'], 'normals': [1704, 'i'], 'ids': [1704, 'i'], 'orientedEnvelope': [93864, 'd'], 'sectionFootprint': [621960, 'd']}\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x00'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m meta, data \u001b[39m=\u001b[39m utk_handler\u001b[39m.\u001b[39;49mread_utk_binary(\u001b[39m'\u001b[39;49m\u001b[39mbuildings\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m./downtown_manhattan 2/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[63], line 188\u001b[0m, in \u001b[0;36mUTKFileHandler.read_utk_binary\u001b[0;34m(self, filename, filepath)\u001b[0m\n\u001b[1;32m    186\u001b[0m field_size, field_type \u001b[39m=\u001b[39m field_info\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m field_name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39morientedEnvelope\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msectionFootprint\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> 188\u001b[0m     data[field_name] \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mloads(file\u001b[39m.\u001b[39mread(field_size))\n\u001b[1;32m    189\u001b[0m \u001b[39melif\u001b[39;00m field_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mdiscardFuncInterval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    190\u001b[0m     data[field_name] \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfield_size\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mstruct\u001b[39m.\u001b[39mcalcsize(field_type)\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mfield_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, file\u001b[39m.\u001b[39mread(field_size))\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x00'."
     ]
    }
   ],
   "source": [
    "meta, data = utk_handler.read_utk_binary('buildings', './downtown_manhattan 2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file parks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/parks.json', 'r') as file:\n",
    "    df_parks = json.load(file)\n",
    "attr_parks = utk_handler.create_attribute_dict(df_parks)\n",
    "utk_handler.create_utk_binary(attr_parks, df_parks, 'parks', './downtown_manhattan 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file roads\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/roads.json', 'r') as file:\n",
    "    df_roads = json.load(file)\n",
    "attr_roads = utk_handler.create_attribute_dict(df_roads)\n",
    "utk_handler.create_utk_binary(attr_roads, df_roads, 'roads', './downtown_manhattan 2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file water\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/water.json', 'r') as file:\n",
    "    df_water = json.load(file)\n",
    "attr_water = utk_handler.create_attribute_dict(df_water)\n",
    "utk_handler.create_utk_binary(attr_water, df_water, 'water', './downtown_manhattan 2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file surface\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/surface.json', 'r') as file:\n",
    "    df_surface = json.load(file)\n",
    "attr_surface = utk_handler.create_attribute_dict(df_surface)\n",
    "utk_handler.create_utk_binary(attr_surface, df_surface, 'surface', './downtown_manhattan 2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow_Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file shadow0_buildings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/shadow0_buildings.json', 'r') as file:\n",
    "    df_shadow_buildings = json.load(file)\n",
    "attr_shadow_buildings = utk_handler.create_attribute_dict(df_shadow_buildings)\n",
    "utk_handler.create_utk_binary(attr_shadow_buildings, df_shadow_buildings, 'shadow0_buildings', './downtown_manhattan 2/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow_Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to file shadow0_surface\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./downtown_manhattan 2/shadow0_surface.json', 'r') as file:\n",
    "    df_shadow_surface = json.load(file)\n",
    "attr_shadow_surface = utk_handler.create_attribute_dict(df_shadow_surface)\n",
    "utk_handler.create_utk_binary(attr_shadow_surface, df_shadow_surface, 'shadow0_surface', './downtown_manhattan 2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attr_shadow_surface' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m attr_shadow_surface\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attr_shadow_surface' is not defined"
     ]
    }
   ],
   "source": [
    "attr_shadow_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(attr_shadow_buildings['values'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
